{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffb51bae",
   "metadata": {},
   "source": [
    "# Triplet Network Tutorial\n",
    "\n",
    "This tutorial will walk you through the creation of a Triplet Neural Network, which is often used for tasks like image similarity, signature verification, and one-shot learning. In this case, we will use the MNIST dataset to build the network, which will compare pairs of images and determine whether they belong to the same class or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b4ad47",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries\n",
    "We will start by importing necessary libraries for data manipulation, neural networks, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torch import optim\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40efd9dc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Variaveis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c3762",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "EMBEDDING_SPACE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce6373",
   "metadata": {},
   "source": [
    "## Step 2: Set Up Device\n",
    "Here, we define whether we will be using a GPU (CUDA) or CPU for our computations. If a GPU is available, it will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080822e3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa19b653",
   "metadata": {},
   "source": [
    "## Step 3: Create a Custom Dataset for Triplet Networks\n",
    "We will now create a custom dataset class `TripletDataset`. This dataset will provide pairs of images from the MNIST dataset, where each pair will either belong to the same class or to different classes. The label will indicate whether the images are similar (0 for same class, 1 for different classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06feb812",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the TripletDataset class.\n",
    "        \n",
    "        Args:\n",
    "            data: List of tuples where each tuple contains (image, label).\n",
    "            transform: Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = data  # Store the dataset.\n",
    "        self.transform = transform  # Store the image transformation function.\n",
    "\n",
    "    def _get_image_from_same_class(self, labelA):\n",
    "        labelB = -1\n",
    "        while labelB != labelA:\n",
    "            imgB, labelB = random.choice(self.data)\n",
    "        return imgB, labelB\n",
    "    \n",
    "    def _get_image_from_different_class(self, labelA):\n",
    "        labelB = labelA\n",
    "        while labelB == labelA:\n",
    "            imgB, labelB = random.choice(self.data)\n",
    "        return imgB, labelB\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns a sample from the dataset, consisting of two images and a label indicating\n",
    "        if they belong to the same class.\n",
    "        \n",
    "        Args:\n",
    "            index: Index of the first image in the dataset.\n",
    "        \n",
    "        Returns:\n",
    "            imgA, imgB: A pair of images.\n",
    "            label: A binary tensor indicating whether the images are from the same class (0) \n",
    "                   or different classes (1).\n",
    "        \"\"\"\n",
    "        imgA, labelA = self.data[index]\n",
    "        imgB, _ = self._get_image_from_same_class(labelA)\n",
    "        imgC, _ = self._get_image_from_different_class(labelA)\n",
    "\n",
    "        if self.transform:\n",
    "            imgA = self.transform(imgA)\n",
    "            imgB = self.transform(imgB)\n",
    "            imgC = self.transform(imgC)\n",
    "\n",
    "        return imgA, imgB, imgC\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "\n",
    "mnist_train = MNIST(root='../../data', train=True, download=True)\n",
    "mnist_test = MNIST(root='../../data', train=False, download=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(degrees=10)\n",
    "])\n",
    "\n",
    "triplet_train = TripletDataset(mnist_train, transform)\n",
    "triplet_test = TripletDataset(mnist_test, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe93de28",
   "metadata": {},
   "source": [
    "## Step 4: Visualize the Dataset\n",
    "Let's visualize a few samples of image pairs from our custom `TripletDataset`. This will help us understand how the pairs are generated (same class or different class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f10b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_triplet_samples(dataset, num_samples=5):\n",
    "    \"\"\"\n",
    "    Plots pairs of images from the TripletDataset along with their label indicating\n",
    "    if they belong to the same class or different classes.\n",
    "    \n",
    "    Args:\n",
    "        dataset: An instance of the TripletDataset.\n",
    "        num_samples: Number of image pairs to plot.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(8, num_samples * 2))\n",
    "    fig.suptitle('Triplet Dataset Image Triplets')\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        imgA, imgB, imgC = dataset[random.randint(0, len(dataset)-1)]\n",
    "        imgA = imgA.cpu().squeeze().numpy()\n",
    "        imgB = imgB.cpu().squeeze().numpy()\n",
    "        imgC = imgC.cpu().squeeze().numpy()\n",
    "\n",
    "        axes[i, 0].imshow(imgA, cmap='gray')\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 0].set_title(f'Image A')\n",
    "\n",
    "        axes[i, 1].imshow(imgB, cmap='gray')\n",
    "        axes[i, 1].axis('off')\n",
    "        axes[i, 1].set_title('Image B')\n",
    "\n",
    "        axes[i, 2].imshow(imgC, cmap='gray')\n",
    "        axes[i, 2].axis('off')\n",
    "        axes[i, 2].set_title('Image C')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    plt.savefig('plot_triplet_samples.png')\n",
    "\n",
    "# Example usage:\n",
    "plot_triplet_samples(triplet_train, num_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc0733",
   "metadata": {},
   "source": [
    "## Step 5: Build the Triplet Network Architecture\n",
    "The `TripletNetwork` consists of two branches that share weights. These branches process the two input images, and the results are compared to determine the similarity. The architecture consists of convolutional layers followed by fully connected layers.\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c0bf3",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Tower definition"
   },
   "outputs": [],
   "source": [
    "class Tower(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tower, self).__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256 * 3 * 3, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(256, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.cnn(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46767aca",
   "metadata": {
    "title": "TripletNetwork definition"
   },
   "outputs": [],
   "source": [
    "class TripletNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TripletNetwork, self).__init__()\n",
    "        self.tower = Tower()  # Shared tower network\n",
    "\n",
    "    def forward(self, inputA, inputB, inputC):\n",
    "        outputA = self.tower(inputA)\n",
    "        outputB = self.tower(inputB)\n",
    "        outputC = self.tower(inputC)\n",
    "        return outputA, outputB, outputC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97864ebd",
   "metadata": {},
   "source": [
    "## Step 6: Define the Contrastive Loss Function\n",
    "We use the contrastive loss function to optimize the Triplet Network. This loss function computes the distance between two outputs and penalizes the network based on whether they are from the same class or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6663b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TripletLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        # Calculate distances between anchor-positive and anchor-negative\n",
    "        pos_dist = F.pairwise_distance(anchor, positive, keepdim=True)\n",
    "        neg_dist = F.pairwise_distance(anchor, negative, keepdim=True)\n",
    "\n",
    "        # Calculate the triplet loss\n",
    "        loss = torch.clamp(pos_dist - neg_dist + self.margin, min=0.0)\n",
    "\n",
    "        return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5302136",
   "metadata": {},
   "source": [
    "## Step 7: Training the Network\n",
    "Now we will train the network using the `TripletDataset` and the `ContrastiveLoss`. The training loop involves computing the loss for each image pair and updating the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d32846",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(triplet_train, shuffle=True, batch_size=128,)\n",
    "\n",
    "net = TripletNetwork().to(device)\n",
    "criterion = TripletLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for imgA, imgB, imgC in tqdm(train_dataloader, desc=f\"Train epoch: {epoch+1}\"):\n",
    "        imgA, imgB, imgC = imgA.to(device), imgB.to(device), imgC.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputA, outputB, outputC = net(imgA, imgB, imgC)\n",
    "        loss_contrastive = criterion(outputA, outputB, outputC)\n",
    "        loss_contrastive.backward()\n",
    "\n",
    "        total_loss += loss_contrastive.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch}; Loss {total_loss}\")\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgA, imgB, imgC in dataloader:\n",
    "            imgA, imgB, imgC = imgA.to(device), imgB.to(device), imgC.to(device)\n",
    "            outputA, outputB, outputC = model(imgA, imgB, imgC)\n",
    "\n",
    "            # Calculate the distances\n",
    "            euclidean_distance_pos = F.pairwise_distance(outputA, outputB)\n",
    "            euclidean_distance_neg = F.pairwise_distance(outputA, outputC)\n",
    "\n",
    "            # Assume a threshold for classification\n",
    "            predictions_pos = euclidean_distance_pos < 1.0  # Same class if distance is small\n",
    "            predictions_neg = euclidean_distance_neg > 1.0  # Different class if distance is large\n",
    "\n",
    "            # Count correct predictions\n",
    "            correct_pos = predictions_pos.sum().item()\n",
    "            correct_neg = predictions_neg.sum().item()\n",
    "\n",
    "            total_correct += correct_pos + correct_neg\n",
    "            total_samples += imgA.size(0) * 2  # Two comparisons per triplet\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(triplet_test, shuffle=False, batch_size=64)\n",
    "accuracy = evaluate_model(net, test_dataloader)\n",
    "print(f'Test Dataset Accuracy: {accuracy}%')\n",
    "def plot_triplet_predict_samples(dataset, num_samples=5):\n",
    "    \"\"\"\n",
    "    Plots triplets of images from the TripletDataset along with their predicted label \n",
    "    indicating if imgA and imgB belong to the same class and imgA and imgC to different classes.\n",
    "    \n",
    "    Args:\n",
    "        dataset: An instance of the TripletDataset.\n",
    "        num_samples: Number of image triplets to plot.\n",
    "    \"\"\"\n",
    "    # Set up the plot with 3 columns for triplet images\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(8, num_samples * 2))\n",
    "    fig.suptitle('Triplet Dataset Samples with Predictions')\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Randomly pick an index from the dataset\n",
    "        imgA, imgB, imgC = dataset[random.randint(0, len(dataset) - 1)]\n",
    "        imgA, imgB, imgC = imgA.to(device), imgB.to(device), imgC.to(device)\n",
    "\n",
    "        # Get the model's outputs for each image in the triplet\n",
    "        outputA, outputB, outputC = net(imgA.unsqueeze(0), imgB.unsqueeze(0), imgC.unsqueeze(0))\n",
    "\n",
    "        # Compute pairwise distances (similarity scores)\n",
    "        similarity_score_AB = F.pairwise_distance(outputA, outputB).cpu().item()\n",
    "        similarity_score_AC = F.pairwise_distance(outputA, outputC).cpu().item()\n",
    "\n",
    "        # Convert tensors to numpy arrays for plotting\n",
    "        imgA = imgA.cpu().squeeze().numpy()\n",
    "        imgB = imgB.cpu().squeeze().numpy()\n",
    "        imgC = imgC.cpu().squeeze().numpy()\n",
    "\n",
    "        # Plot imgA (Anchor)\n",
    "        axes[i, 0].imshow(imgA, cmap='gray')\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 0].set_title('Anchor (imgA)')\n",
    "\n",
    "        # Plot imgB (Positive)\n",
    "        axes[i, 1].imshow(imgB, cmap='gray')\n",
    "        axes[i, 1].axis('off')\n",
    "        axes[i, 1].set_title(f'Positive (imgB)\\nScore: {similarity_score_AB:.2f}')\n",
    "\n",
    "        # Plot imgC (Negative)\n",
    "        axes[i, 2].imshow(imgC, cmap='gray')\n",
    "        axes[i, 2].axis('off')\n",
    "        axes[i, 2].set_title(f'Negative (imgC)\\nScore: {similarity_score_AC:.2f}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    plt.savefig('plot_triplet_predicted_samples.png')\n",
    "\n",
    "# Example call to the function\n",
    "plot_triplet_predict_samples(triplet_test, num_samples=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3e0293",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Salva Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd3a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o modelo da Tower\n",
    "torch.save(net.tower.state_dict(), 'tower_model_triplet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7949606",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Step 8: Test the Network\n",
    "Let's test the network on a few image pairs from the test dataset and visualize the similarity scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80698df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o modelo da Tower\n",
    "tower_model = Tower().to(device)  # Ensure model is on the same device\n",
    "tower_model.load_state_dict(torch.load('tower_model_triplet.pth', map_location=device))  # Load weights directly onto the device\n",
    "tower_model.eval()  # Colocar o modelo em modo de avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10e1fe",
   "metadata": {},
   "source": [
    "## Step 8: Test the Network\n",
    "Let's test the network on a few image pairs from the test dataset and visualize the similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fc912",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = MNIST(root='../../data', train=False, download=True)\n",
    "test_tensor = torch.utils.data.TensorDataset(torch.tensor(mnist_test.data), torch.tensor(mnist_test.targets))\n",
    "# Create a data loader from the tensor dataset\n",
    "test_loader = torch.utils.data.DataLoader(test_tensor, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "# EVAL USANDO TOWER:\n",
    "for imgA, label in test_tensor:\n",
    "    imgA = imgA.type(torch.float32).unsqueeze(0).unsqueeze(0).to(device)  \n",
    "    outputA = tower_model(imgA)\n",
    "    print(outputA)\n",
    "    break\n",
    "\n",
    "for imgA, label in test_loader:\n",
    "    imgA = imgA.type(torch.float32).unsqueeze(0).to(device)  \n",
    "    outputA = tower_model(imgA)\n",
    "    print(outputA)\n",
    "    break\n",
    "\n",
    "\n",
    "## Visualize the embeddings.\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Define a function to extract embeddings from the tower model\n",
    "# Create a data loader from the tensor dataset\n",
    "# Define a function to extract embeddings from the tower model\n",
    "def extract_embeddings(loader, model, device):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.type(torch.float32)\n",
    "            x = x.to(device)\n",
    "            output = model(x.unsqueeze(0))\n",
    "            embeddings.append(output.cpu().numpy())\n",
    "            labels.append(y.cpu().numpy())\n",
    "    return np.concatenate(embeddings), np.concatenate(labels)\n",
    "\n",
    "embeddings, labels = extract_embeddings(test_loader, tower_model, device)\n",
    "\n",
    "# Extract embeddings from the tower model\n",
    "tower_model.eval()\n",
    "embeddings, labels = extract_embeddings(test_loader, tower_model, device)\n",
    "\n",
    "\n",
    "# Use t-SNE to reduce the dimensionality of the embeddings\n",
    "def visualizate_embeddings(embeddings, labels, annotation_sample=.06):\n",
    "    # Use t-SNE to reduce the dimensionality of the embeddings\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "    # Plot the embedding space\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=labels)\n",
    "\n",
    "    # Sample x% of the labels for annotation\n",
    "    sample_idx = np.random.choice(range(len(labels)), size=int(annotation_sample * len(labels)), replace=False)\n",
    "    for i in sample_idx:\n",
    "        x, y = embeddings_2d[i, 0], embeddings_2d[i, 1]\n",
    "        plt.annotate(str(labels[i]), (x, y), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "    plt.title('MNIST Embedding Space')\n",
    "    plt.xlabel('Dimension 1')\n",
    "    plt.ylabel('Dimension 2')\n",
    "    plt.colorbar()\n",
    "    plt.savefig('MNIST Embedding Space_tiplet_loss.png')\n",
    "\n",
    "visualizate_embeddings(embeddings, labels)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
